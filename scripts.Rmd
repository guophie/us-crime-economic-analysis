---
title: "Analysis of U.S. Crime and Economic Data"
author: "Sophie Guo"
output:
  html_document:
    df_print: paged
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
library(dplyr)
library(tidyverse)
library(modelr)
library(broom)
library(leaps)
library(gridExtra)
library(kableExtra)
options(readr.show_col_types = FALSE)
```

## Preview of the dataset 
```{r, echo = FALSE, message = FALSE}
DATA = read_csv("data.csv") %>%
  rename(prisoner_count_per_million = prisoner_count_per_milion)

head(DATA)
```

# Question 1: Can we use crime data to predict a state's poverty rate?
```{r, include = FALSE}
# Error metrics for regression model evaluation 
MSE.func = function(resid){
  return(mean(resid^2))
}

RMSE.func = function(resid){
  return(sqrt(mean(resid^2)))
}

MAE.func = function(resid){
  return(mean(abs(resid)))
}
```

```{r, include = FALSE}
model_data = DATA %>%
  select(-c(1:12, 17, 24:29, 31)) %>%
  na.exclude()
```

## Stepwise regression model (no-way interactions) for poverty rate
```{r, include = FALSE}
Full = lm(Total~., data = model_data)
none = lm(Total~1, data = model_data)
MSE = (summary(Full)$sigma)^2

step(none, scope=list(upper=Full), scale = MSE, trace = FALSE)
```

```{r, echo = FALSE}
stepwise_model = lm(Total~burglary_per_million + property_crime_per_million + murder_manslaughter_per_million + robbery_per_million + rape_legacy_per_million + prisoner_count_per_million, data = model_data)

stepwise_model
```

```{r, warning = FALSE, include = FALSE}
# Cross-Validation: Splitting the data and fitting the model
train.model.func=function(data){
  mod = lm(Total~burglary_per_million + property_crime_per_million + murder_manslaughter_per_million + robbery_per_million + rape_legacy_per_million + prisoner_count_per_million, data = data)
  return(mod)
}

model_data2 = model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest()
```

## Stepwise regression model (2-way interactions)
```{r, include = FALSE}
Full2 = lm(Total~.*., data = model_data)
none2 = lm(Total~1, data = model_data)
MSE2 = (summary(Full)$sigma)^2

step(none2, scope=list(upper=Full2), scale = MSE2, trace = FALSE)
```

```{r, echo = FALSE}
stepwise_2way_model = lm(Total ~ burglary_per_million + property_crime_per_million + 
    murder_manslaughter_per_million + robbery_per_million + rape_legacy_per_million + 
    violent_crime_per_million + agg_assault_per_million + murder_manslaughter_per_million:robbery_per_million + 
    burglary_per_million:property_crime_per_million + rape_legacy_per_million:violent_crime_per_million + 
    murder_manslaughter_per_million:agg_assault_per_million + 
    burglary_per_million:murder_manslaughter_per_million + violent_crime_per_million:agg_assault_per_million, 
    data = model_data)

stepwise_2way_model
```

```{r, warning = FALSE, include = FALSE}
# Cross-Validation: Splitting the data and fitting the model
train.model.func2=function(data){
  mod = lm(Total ~ burglary_per_million + property_crime_per_million + 
    murder_manslaughter_per_million + robbery_per_million + rape_legacy_per_million + 
    violent_crime_per_million + agg_assault_per_million + murder_manslaughter_per_million:robbery_per_million + 
    burglary_per_million:property_crime_per_million + rape_legacy_per_million:violent_crime_per_million + 
    murder_manslaughter_per_million:agg_assault_per_million + 
    burglary_per_million:murder_manslaughter_per_million + violent_crime_per_million:agg_assault_per_million, 
    data = data)
  return(mod)
}

model_data3 = model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func2),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest()
```

## Multiple regression models: two predictors
**M1**: burglary_per_million + murder_manslaughter_per_million

**M2**: burglary_per_million + robbery_per_million

**M3**: property_crime_per_million + robbery_per_million

**M4**: murder_manslaughter_per_million + property_crime_per_million

**M5**: burglary_per_million + rape_legacy_per_million

```{r, include = FALSE}
# Multiple Models (M1-M5): Multiple regression model with two predictors
M1 = lm(Total~burglary_per_million+murder_manslaughter_per_million, data = model_data)
```

```{r, warning = FALSE, include = FALSE}
train.model.func3=function(data){
  mod = lm(Total~burglary_per_million+murder_manslaughter_per_million, data = data)
  return(mod)
}

model_data4 = model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func3),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest()
```

```{r, include = FALSE}
M2 = lm(Total~burglary_per_million+robbery_per_million, data = model_data)
```

```{r, warning = FALSE, include = FALSE}
train.model.func4=function(data){
  mod = lm(Total~burglary_per_million+robbery_per_million, data = data)
  return(mod)
}

model_data5 = model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func4),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest()
```

```{r, include = FALSE}
M3 = lm(Total~property_crime_per_million+robbery_per_million, data = model_data)
```

```{r, warning = FALSE, include = FALSE}
train.model.func5=function(data){
  mod = lm(Total~property_crime_per_million+robbery_per_million, data = data)
  return(mod)
}

model_data6 = model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func5),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest()
```

```{r, include = FALSE}
M4 = lm(Total~murder_manslaughter_per_million+property_crime_per_million, data = model_data)
```

```{r, warning = FALSE, include = FALSE}
train.model.func6=function(data){
  mod = lm(Total~murder_manslaughter_per_million+property_crime_per_million, data = data)
  return(mod)
}

model_data7 = model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func6),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest()
```

```{r, include = FALSE}
M5 = lm(Total~burglary_per_million+rape_legacy_per_million, data = model_data)
```

```{r, warning = FALSE, include = FALSE}
train.model.func7=function(data){
  mod = lm(Total~burglary_per_million+rape_legacy_per_million, data = data)
  return(mod)
}

model_data8 = model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func7),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest()
```

## Performance metrics for the varying models
```{r, echo = FALSE}
model_metrics = tibble(
  Model = c("SW (no-way)", "SW (2-way)", "M1", "M2", "M3", "M4", "M5"),
  RMSE = c(RMSE.func(model_data2$.resid), 
           RMSE.func(model_data3$.resid), 
           RMSE.func(model_data4$.resid),
           RMSE.func(model_data5$.resid),
           RMSE.func(model_data6$.resid),
           RMSE.func(model_data7$.resid),
           RMSE.func(model_data8$.resid)),
  MSE = c(MSE.func(model_data2$.resid), 
          MSE.func(model_data3$.resid), 
          MSE.func(model_data4$.resid),
          MSE.func(model_data5$.resid),
          MSE.func(model_data6$.resid),
          MSE.func(model_data7$.resid),
          MSE.func(model_data8$.resid)),
  MAE = c(MAE.func(model_data2$.resid), 
          MAE.func(model_data3$.resid), 
          MAE.func(model_data4$.resid),
          MAE.func(model_data5$.resid),
          MAE.func(model_data6$.resid),
          MAE.func(model_data7$.resid),
          MAE.func(model_data8$.resid)),
  Adj.R.Squared = c(summary(stepwise_model)$adj.r.squared,
                    summary(stepwise_2way_model)$adj.r.squared,
                    summary(M1)$adj.r.squared,
                    summary(M2)$adj.r.squared,
                    summary(M3)$adj.r.squared,
                    summary(M4)$adj.r.squared,
                    summary(M5)$adj.r.squared))
    
model_metrics %>%
  kbl(caption = "Comparsion of models predicting poverty rate") %>%
  kable_styling()
```
```{r, echo = FALSE}
RMSE_plot = model_metrics %>%
  ggplot(aes(Model, RMSE)) +
  geom_bar(stat="identity", fill = rep(c("darkred", "tan"), length.out = 7)) +
  guides(x = guide_axis(angle = 90)) +
  theme_minimal()

MSE_plot = model_metrics %>%
  ggplot(aes(Model, MSE)) +
  geom_bar(stat="identity", fill = rep(c("darkred", "tan"), length.out = 7)) +
  guides(x = guide_axis(angle = 90)) +
  theme_minimal()

MAE_plot = model_metrics %>%
  ggplot(aes(Model, MAE)) +
  geom_bar(stat="identity", fill = rep(c("darkred", "tan"), length.out = 7)) +
  guides(x = guide_axis(angle = 90)) +
  theme_minimal()

ADJRSQ_plot = model_metrics %>%
  ggplot(aes(Model, Adj.R.Squared)) +
  geom_bar(stat="identity", fill = rep(c("darkred", "tan"), length.out = 7)) +
  guides(x = guide_axis(angle = 90)) +
  theme_minimal()

grid.arrange(RMSE_plot, MSE_plot, MAE_plot, ADJRSQ_plot,
             layout_matrix=matrix(c(1,3,2,4),ncol=2), top = "Performance Metrics for Poverty Rate Models")
```

```{r, echo = FALSE}
# Stepwise (no-way) Model Plot
stepwise_model_line = lm(.fitted~Total, data = model_data2)
B0 = summary(stepwise_model_line)$coef[1]
B1 = summary(stepwise_model_line)$coef[2]
  
ggplot(model_data2) +
  geom_point(aes(x= Total, y = .fitted)) + 
  geom_abline(intercept = B0, slope = B1, col = "darkred") +
  geom_abline(intercept = 0, slope = 1, col = "tan") + 
  xlab("Actual Poverty Rate") + ylab("Predicted Poverty Rate") +
  ggtitle("Stepwise regression (no-way) model") +
  theme_minimal()

# Stepwise (2-way) Model Plot
stepwise_2way_model_line = lm(.fitted~Total, data = model_data3)
B0_2 = summary(stepwise_2way_model_line)$coef[1]
B1_2 = summary(stepwise_2way_model_line)$coef[2]
  
ggplot(model_data3) +
  geom_point(aes(x= Total, y = .fitted)) + 
  geom_abline(intercept = B0_2, slope = B1_2, col = "darkred") +
  geom_abline(intercept = 0, slope = 1, col = "tan") + 
  xlab("Actual Poverty Rate") + ylab("Predicted Poverty Rate") +
  ggtitle("Stepwise regression (2-way) model") +
  theme_minimal()
```

# Question 2: Can we use economic and crime data to predict whether a state's minimum wage will be lower than the federal minimum wage?

```{r, include = FALSE}
# Creating a binary variable that compares a state's minimum wage relative to the federal minimum wage
log_model_data = DATA %>%
  select(-c(1:11))

col = c(rep(NA, nrow(DATA)))

for(i in 1:nrow(DATA)){
  col[i] = ifelse(DATA$State.Min.Wage[i] < DATA$Fed.Min.Wage[i], 1, 0)
}

log_model_data$State.Lower.Than.Fed = col
```

## Identifying predictors: Test for overall fit using the G statistic
```{r, echo = FALSE}
# Test for overall fit using the G statistic.
# Logistic regression: Model 1
greatestG = 0

for(i in names(log_model_data)[-21]){
  new = glm(State.Lower.Than.Fed~eval(sym(i)), family = binomial, data = log_model_data)
  G = summary(new)$null.deviance - summary(new)$deviance
  cat("The G statistic of", i, "is", G, ".\n")
  greatestG = ifelse(G > greatestG, G, greatestG)
}
```
## Logistic regression models
**Model 1**: median_income

**Model 2**: median_income + Total + median_income*Total

**Model 3**: median_income + Total + burglary_per_million

**Model 4**: median_income + Total + burglary_per_million + Total*burglary_per_million

```{r, warning = FALSE, include = FALSE}
# Cross-Validation: Splitting the data and fitting the model
train.model.func8=function(data){
  mod = glm(State.Lower.Than.Fed~median_income, family = binomial, data = data)
  return(mod)
}

log_model_data2 = log_model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func8),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest() %>%
  mutate(odds = exp(.fitted), 
         p = odds/(1+odds),
         prediction = ifelse(p >= 0.5, 1, 0))
```

```{r, include = FALSE}
# Confusion Matrix
factor_data = function(data){
  return(data %>%
  select(State.Lower.Than.Fed, prediction) %>%
  mutate(State.Lower.Than.Fed = factor(State.Lower.Than.Fed), 
         prediction = factor(prediction)) %>%
  mutate(State.Lower.Than.Fed = fct_recode(State.Lower.Than.Fed, "State<Fed" = "1", "State>=Fed" = "0"),
         prediction = fct_recode(prediction, "State<Fed" = "1", "State>=Fed" = "0")) %>%
  mutate(State.Lower.Than.Fed = factor(State.Lower.Than.Fed, levels = c("State<Fed", "State>=Fed")),
         prediction = factor(prediction, levels = c("State<Fed", "State>=Fed"))))
}

log_model_data3 = factor_data(log_model_data2)
head(log_model_data3)
```

```{r, include = FALSE}
log_model_results = table(log_model_data3$State.Lower.Than.Fed, log_model_data3$prediction) %>%
  prop.table()

print(log_model_results)
```

```{r, include = FALSE}
# Logistic regression: Model 2
log2_model = glm(State.Lower.Than.Fed~median_income+Total+median_income*Total, family = binomial, data = log_model_data)
```

```{r, warning = FALSE, include = FALSE}
# Cross-Validation: Splitting the data and fitting the model
train.model.func9=function(data){
  mod = glm(State.Lower.Than.Fed~median_income+Total+median_income*Total, family = binomial, data = data)
  return(mod)
}

log_model_data4 = log_model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func9),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest() %>%
  mutate(odds = exp(.fitted), 
         p = odds/(1+odds),
         prediction = ifelse(p >= 0.5, 1, 0))
```

```{r, include = FALSE}
# Confusion Matrix
log_model_results2 = table(factor_data(log_model_data4)$State.Lower.Than.Fed, factor_data(log_model_data4)$prediction) %>%
  prop.table()

print(log_model_results2)
```

```{r, include = FALSE}
# Logistic regression: Model 3
log3_model = glm(State.Lower.Than.Fed~median_income+Total+burglary_per_million, family = binomial, data = log_model_data)
```

```{r, warning = FALSE, include = FALSE}
# Cross-Validation: Splitting the data and fitting the model
train.model.func10=function(data){
  mod = glm(State.Lower.Than.Fed~median_income+Total+burglary_per_million, family = binomial, data = data)
  return(mod)
}

log_model_data5 = log_model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func10),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest() %>%
  mutate(odds = exp(.fitted), 
         p = odds/(1+odds),
         prediction = ifelse(p >= 0.5, 1, 0))
```

```{r, include = FALSE}
# Confusion Matrix
log_model_results3 = table(factor_data(log_model_data5)$State.Lower.Than.Fed, factor_data(log_model_data5)$prediction) %>%
  prop.table()

print(log_model_results3)
```

```{r, include = FALSE}
# Logistic regression: Model 4
log4_model = glm(State.Lower.Than.Fed~median_income+Total+burglary_per_million+Total*burglary_per_million, family = binomial, data = log_model_data)
```

```{r, warning = FALSE, include = FALSE}
# Cross-Validation: Splitting the data and fitting the model
train.model.func11=function(data){
  mod = glm(State.Lower.Than.Fed~median_income+Total+burglary_per_million+Total*burglary_per_million, family = binomial, data = data)
  return(mod)
}

log_model_data6 = log_model_data %>%
  crossv_kfold(5) %>%
  mutate(tr.model = map(train, train.model.func11),
        predict = map2(test, tr.model, ~augment(.y,newdata=.x))) %>%
        select(predict) %>%
        unnest() %>%
  mutate(odds = exp(.fitted), 
         p = odds/(1+odds),
         prediction = ifelse(p >= 0.5, 1, 0))
```

```{r, include = FALSE}
# Confusion Matrix
log_model_results4 = table(factor_data(log_model_data6)$State.Lower.Than.Fed, factor_data(log_model_data6)$prediction) %>%
  prop.table()

print(log_model_results4)
```

## Error metrics for logistic model evaluation
```{r, echo = FALSE}
error.stats = tibble(
  Model = c("Model 1", "Model 2", "Model 3", "Model 4"),
  Sensitivity = c(log_model_results[1,1]/sum(log_model_results[1,]),
                  log_model_results2[1,1]/sum(log_model_results2[1,]),
                  log_model_results3[1,1]/sum(log_model_results3[1,]),
                  log_model_results4[1,1]/sum(log_model_results4[1,])),
  Specificity = c(log_model_results[2,2]/sum(log_model_results[2,]),
                  log_model_results2[2,2]/sum(log_model_results2[2,]),
                  log_model_results3[2,2]/sum(log_model_results3[2,]),
                  log_model_results4[2,2]/sum(log_model_results4[2,])),
  FPR = c(log_model_results[2, 1]/sum(log_model_results[2,]),
          log_model_results2[2, 1]/sum(log_model_results2[2,]),
          log_model_results3[2, 1]/sum(log_model_results3[2,]),
          log_model_results4[2, 1]/sum(log_model_results4[2,])),
  FNR = c(log_model_results[1,2]/sum(log_model_results[1,]),
          log_model_results2[1,2]/sum(log_model_results2[1,]),
          log_model_results3[1,2]/sum(log_model_results3[1,]),
          log_model_results4[1,2]/sum(log_model_results4[1,])))


error.stats %>%
  kbl(caption = "Comparsion of logistic regression models") %>%
  kable_styling()
```

